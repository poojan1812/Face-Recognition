{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 224\n",
    "img_cols = 224 #vgg bts user 224*224 image \n",
    "\n",
    "#loading dataset\n",
    "model = VGG16(weights = 'imagenet', include_top=False, input_shape = ( img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D True\n",
      "2 Conv2D True\n",
      "3 MaxPooling2D True\n",
      "4 Conv2D True\n",
      "5 Conv2D True\n",
      "6 MaxPooling2D True\n",
      "7 Conv2D True\n",
      "8 Conv2D True\n",
      "9 Conv2D True\n",
      "10 MaxPooling2D True\n",
      "11 Conv2D True\n",
      "12 Conv2D True\n",
      "13 Conv2D True\n",
      "14 MaxPooling2D True\n",
      "15 Conv2D True\n",
      "16 Conv2D True\n",
      "17 Conv2D True\n",
      "18 MaxPooling2D True\n"
     ]
    }
   ],
   "source": [
    "#displaying total layers\n",
    "for ( i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creting layer \n",
    "def modeladd(bottom_model, num_classes, D=512):\n",
    "  top_model = bottom_model.output\n",
    "  top_model = Flatten(name = \"flatten\")(top_model)\n",
    "  top_model = Dense(D, activation = \"relu\")(top_model)\n",
    "  top_model = Dense(1024,activation='relu')(top_model)\n",
    "  top_model = Dense(1024,activation='relu')(top_model)\n",
    "  top_model = Dropout(0.3)(top_model)\n",
    "  top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
    "\n",
    "  return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 29,137,218\n",
      "Trainable params: 29,137,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "FC_Head = modeladd(model, num_classes)\n",
    "\n",
    "newmodel = Model(inputs=model.input, outputs=FC_Head)\n",
    "\n",
    "print(newmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'faces/train/'\n",
    "test_data_dir = 'faces/test/'\n",
    "\n",
    "#data augmentation\n",
    "train_genimg = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "test_genimg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#changing batch size\n",
    "train_batch = 16\n",
    "test_batch = 10\n",
    "\n",
    "train_generate = train_genimg.flow_from_directory(\n",
    " train_data_dir,\n",
    " target_size = (img_rows, img_cols),\n",
    " batch_size = train_batch,\n",
    " class_mode = 'categorical')\n",
    "\n",
    "test_generate = test_genimg.flow_from_directory(\n",
    " test_data_dir,\n",
    "target_size = (img_rows, img_cols),\n",
    "batch_size = test_batch,\n",
    "class_mode = 'categorical',\n",
    "shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7102 - accuracy: 0.5714 - val_loss: 162120.2188 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 162120.21875, saving model to face_VGG.h5\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 12s 12s/step - loss: 140016.8906 - accuracy: 0.5625 - val_loss: 3222.3774 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 162120.21875 to 3222.37744, saving model to face_VGG.h5\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 11s 11s/step - loss: 3151.3555 - accuracy: 0.5000 - val_loss: 8.0969 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss improved from 3222.37744 to 8.09687, saving model to face_VGG.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import  ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"face_VGG.h5\",\n",
    "                                   monitor = \"val_loss\",\n",
    "                                   mode=\"min\",\n",
    "                                   save_best_only = True,\n",
    "                                   verbose = 1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                         min_delta = 0,\n",
    "                         patience = 3 ,\n",
    "                         verbose = 2,\n",
    "                         restore_best_weights = True)\n",
    "\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "newmodel.compile(loss = 'categorical_crossentropy',\n",
    "                optimizer = RMSprop(lr=0.001),\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 30\n",
    "nb_test_samples = 10\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "history = newmodel.fit_generator(\n",
    "train_generate,\n",
    "steps_per_epoch = nb_train_samples // batch_size,\n",
    "epochs=epochs,\n",
    "callbacks=callbacks,\n",
    "validation_data =test_generate,\n",
    "validation_steps = nb_test_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('face_VGG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class -virat face\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "face_dic = { \"[0]\": \"virat\" ,\n",
    "            \"[1]\": \"rohit\"\n",
    "    \n",
    "}\n",
    "\n",
    "face_dic_n = { \"virat\": \"virat face\",\n",
    "             \"rohit\": \"rohit face\"}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    human = face_dic[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    cv2.putText(expanded_image, human, (20,60), cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "    \n",
    "def getRandomImage(path):\n",
    "    folders = list(filter(lambda x:os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"class -\" + face_dic_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+ \"/\" +image_name)\n",
    "\n",
    "for i in range(0,2):\n",
    "    input_im = getRandomImage(\"faces/test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
